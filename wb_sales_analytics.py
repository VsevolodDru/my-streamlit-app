import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import json
from datetime import datetime, date, timedelta
import pytz
import numpy as np
import io
from openpyxl import Workbook
import requests
import gc
import logging
from typing import Optional, Tuple
import tempfile
import os
import traceback
import time

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
os.environ['STREAMLIT_SERVER_ENABLE_WATCHER'] = 'false'
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    layout="wide",
    page_title="WB Analytics Pro",
    page_icon="üìà",
    initial_sidebar_state="expanded"
)

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
MAX_RETRIES = 3
RETRY_DELAY = 5
MAX_JSON_SIZE_MB = 500
JSON_LOAD_TIMEOUT = 600
CHUNK_SIZE = 1024 * 1024

class DataLoader:
    @staticmethod
    def load_with_retry(url: str, loader_func, **kwargs):
        for attempt in range(MAX_RETRIES):
            try:
                return loader_func(url, **kwargs)
            except Exception as e:
                logger.error(f"Attempt {attempt + 1} failed: {str(e)}\n{traceback.format_exc()}")
                if attempt < MAX_RETRIES - 1:
                    time.sleep(RETRY_DELAY)
        return pd.DataFrame()

    @staticmethod
    def load_large_json(url: str) -> pd.DataFrame:
        try:
            logger.info(f"Starting JSON load from {url}")
            
            with requests.head(url, timeout=10) as r:
                if r.status_code != 200:
                    st.error(f"URL –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ö–æ–¥ —Å—Ç–∞—Ç—É—Å–∞: {r.status_code}")
                    return pd.DataFrame()

            progress_bar = st.progress(0)
            status_text = st.empty()
            
            response = requests.get(url, stream=True, timeout=(30, JSON_LOAD_TIMEOUT))
            response.raise_for_status()
            
            chunks = []
            total_size = int(response.headers.get('content-length', 0))
            downloaded = 0
            
            for chunk in response.iter_content(chunk_size=CHUNK_SIZE):
                chunks.append(chunk)
                downloaded += len(chunk)
                progress = min(downloaded / total_size, 1.0) if total_size > 0 else 0
                progress_bar.progress(progress)
                status_text.text(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ: {downloaded/(1024*1024):.1f} –ú–ë / {total_size/(1024*1024):.1f} –ú–ë")
            
            status_text.text("–û–±—Ä–∞–±–æ—Ç–∫–∞ JSON...")
            
            try:
                data = json.loads(b''.join(chunks).decode('utf-8'))
            except json.JSONDecodeError as e:
                st.error(f"–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ JSON: {str(e)}")
                return pd.DataFrame()
            
            if not data:
                st.warning("–ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π JSON")
                return pd.DataFrame()
            
            try:
                df = pd.DataFrame(data)
                if df.empty:
                    st.warning("–î–∞–Ω–Ω—ã–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ JSON")
                    return df
                
                datetime_cols = ['date', 'lastChangeDate']
                for col in datetime_cols:
                    if col in df.columns:
                        try:
                            df[col] = pd.to_datetime(df[col], errors='coerce')
                            if df[col].dt.tz is None:
                                df[col] = df[col].dt.tz_localize('Europe/Moscow')
                        except Exception as e:
                            logger.warning(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞—Ç—ã –≤ –∫–æ–ª–æ–Ω–∫–µ {col}: {str(e)}")
                            df[col] = pd.to_datetime(df[col], errors='coerce')
                
                df['is_return'] = df.get('srid', '').astype(str).str.startswith('R')
                df['revenue'] = df.get('totalPrice', 0)
                
                if 'date' in df.columns:
                    try:
                        df['week'] = df['date'].dt.isocalendar().week
                        df['month'] = df['date'].dt.month
                    except:
                        pass
                
                df['isCancel'] = df.get('isCancel', False)

                column_mapping = {
                    'date': '–î–∞—Ç–∞',
                    'warehouseName': '–°–∫–ª–∞–¥',
                    'warehouse': '–°–∫–ª–∞–¥',
                    'warehouseType': '–¢–∏–ø —Å–∫–ª–∞–¥–∞',
                    'regionName': '–†–µ–≥–∏–æ–Ω',
                    'category': '–ö–∞—Ç–µ–≥–æ—Ä–∏—è',
                    'brand': '–ë—Ä–µ–Ω–¥',
                    'subject': '–ü–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è',
                    'totalPrice': '–¶–µ–Ω–∞',
                    'revenue': '–í—ã—Ä—É—á–∫–∞',
                    'spp': '–°–ü–ü',
                    'supplierArticle': '–ê—Ä—Ç–∏–∫—É–ª'
                }
                
                df = df.rename(columns={k: v for k, v in column_mapping.items() if k in df.columns})

                str_cols = ['–ë—Ä–µ–Ω–¥', '–ê—Ä—Ç–∏–∫—É–ª', '–ö–∞—Ç–µ–≥–æ—Ä–∏—è', '–ü–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è', '–°–∫–ª–∞–¥', '–¢–∏–ø —Å–∫–ª–∞–¥–∞']
                for col in str_cols:
                    if col in df.columns:
                        df[col] = df[col].astype(str).str.strip()
                
                if '–ë—Ä–µ–Ω–¥' in df.columns:
                    df['–ë—Ä–µ–Ω–¥'] = df['–ë—Ä–µ–Ω–¥'].str.lower()
                
                if '–ê—Ä—Ç–∏–∫—É–ª' in df.columns:
                    df['–ê—Ä—Ç–∏–∫—É–ª'] = df['–ê—Ä—Ç–∏–∫—É–ª'].apply(
                        lambda x: x[:len(x)//2] if isinstance(x, str) and len(x) == 20 and x[:10] == x[10:] else x
                    )

                logger.info(f"–£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π")
                return df
                
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
                return pd.DataFrame()
                
        except Exception as e:
            logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {str(e)}\n{traceback.format_exc()}")
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
            return pd.DataFrame()
        finally:
            if 'progress_bar' in locals(): progress_bar.empty()
            if 'status_text' in locals(): status_text.empty()

    @staticmethod
    def load_excel_data(url: str) -> pd.DataFrame:
        try:
            logger.info(f"Starting Excel load from {url}")
            
            try:
                with requests.head(url, timeout=10) as r:
                    if r.status_code != 200:
                        st.error(f"Excel URL –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ö–æ–¥ —Å—Ç–∞—Ç—É—Å–∞: {r.status_code}")
                        return pd.DataFrame()
            except requests.RequestException as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Excel URL: {str(e)}")
                return pd.DataFrame()

            response = requests.get(url, timeout=(30, 300))
            response.raise_for_status()
            
            with io.BytesIO(response.content) as excel_file:
                try:
                    df = pd.read_excel(
                        excel_file,
                        usecols=['–ê—Ä—Ç–∏–∫—É–ª –ø—Ä–æ–¥–∞–≤—Ü–∞', '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ'],
                        dtype={'–ê—Ä—Ç–∏–∫—É–ª –ø—Ä–æ–¥–∞–≤—Ü–∞': 'string', '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ': 'string'}
                    )
                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è Excel: {str(e)}")
                    return pd.DataFrame()
            
            if df.empty:
                st.warning("Excel —Ñ–∞–π–ª –ø—É—Å—Ç")
                return df
            
            required_cols = ['–ê—Ä—Ç–∏–∫—É–ª –ø—Ä–æ–¥–∞–≤—Ü–∞', '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ']
            if not all(col in df.columns for col in required_cols):
                st.error("–í Excel –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏")
                return pd.DataFrame()
            
            df = df.rename(columns={
                '–ê—Ä—Ç–∏–∫—É–ª –ø—Ä–æ–¥–∞–≤—Ü–∞': '–ê—Ä—Ç–∏–∫—É–ª',
                '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ': '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞'
            })
            
            df['–ê—Ä—Ç–∏–∫—É–ª'] = df['–ê—Ä—Ç–∏–∫—É–ª'].astype(str).str.strip()
            df['–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞'] = df['–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞'].astype(str).str.strip()
            
            logger.info(f"Excel –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã. –†–∞–∑–º–µ—Ä: {len(df)} —Å—Ç—Ä–æ–∫")
            return df[['–ê—Ä—Ç–∏–∫—É–ª', '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞']].drop_duplicates(subset=['–ê—Ä—Ç–∏–∫—É–ª'])
        
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Excel: {str(e)}\n{traceback.format_exc()}")
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ Excel —Ñ–∞–π–ª–∞: {str(e)}")
            return pd.DataFrame()

def main():
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è
    if 'data_loaded' not in st.session_state:
        st.session_state.update({
            'data_loaded': False,
            'load_error': None,
            'df': pd.DataFrame(),
            'excel_df': pd.DataFrame(),
            'filtered_df': pd.DataFrame()
        })

    st.title("üîç Wildberries Analytics Pro")
    
    # URL –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
    DATA_SOURCES = {
        "json": "https://storage.yandexcloud.net/my-json-bucket-chat-wb/wb_dashboard/all_sales_data.json",
        "excel": "https://storage.yandexcloud.net/my-json-bucket-chat-wb/14_04_2025_07_26_%D0%9E%D0%B1%D1%89%D0%B8%D0%B5_%D1%85%D0%B0%D1%80%D0%B0%D0%BA%D1%82%D0%B5%D1%80%D0%B8%D1%81%D1%82%D0%B8%D0%BA%D0%B8_%D0%BE%D0%B4%D0%BD%D0%B8%D0%BC_%D1%84%D0%B0%D0%B9%D0%BB%D0%BE%D0%BC.xlsx"
    }

    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    if not st.session_state.data_loaded and st.session_state.load_error is None:
        with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ..."):
            try:
                json_data = DataLoader.load_with_retry(DATA_SOURCES["json"], DataLoader.load_large_json)
                
                if not json_data.empty:
                    excel_data = DataLoader.load_with_retry(DATA_SOURCES["excel"], DataLoader.load_excel_data)
                    
                    if not excel_data.empty:
                        try:
                            merged_df = pd.merge(
                                json_data,
                                excel_data,
                                on='–ê—Ä—Ç–∏–∫—É–ª',
                                how='left'
                            )
                            st.session_state.update({
                                'df': merged_df,
                                'excel_df': excel_data,
                                'data_loaded': True,
                                'load_error': None
                            })
                        except Exception as e:
                            st.session_state.load_error = f"–û—à–∏–±–∫–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {str(e)}"
                    else:
                        st.session_state.update({
                            'df': json_data,
                            'data_loaded': True,
                            'load_error': "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å Excel –¥–∞–Ω–Ω—ã–µ"
                        })
                else:
                    st.session_state.load_error = "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ"
                    
            except Exception as e:
                st.session_state.load_error = f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}"
                logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {str(e)}\n{traceback.format_exc()}")

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –∑–∞–≥—Ä—É–∑–∫–∏
    if st.session_state.load_error:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {st.session_state.load_error}")
        
        if st.button("–ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Å–Ω–æ–≤–∞"):
            st.session_state.update({
                'data_loaded': False,
                'load_error': None
            })
            st.rerun()
        
        st.stop()
    
    if not st.session_state.data_loaded:
        st.warning("–î–∞–Ω–Ω—ã–µ –µ—â–µ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è...")
        st.stop()

    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ session state
    df = st.session_state.df
    excel_df = st.session_state.excel_df

    # –ö–Ω–æ–ø–∫–∞ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
    if st.button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ"):
        st.session_state.update({
            'data_loaded': False,
            'load_error': None
        })
        st.rerun()

    # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –¥–∞—Ç
    try:
        if not df.empty and '–î–∞—Ç–∞' in df.columns:
            min_date = df['–î–∞—Ç–∞'].min().date()
            max_date = df['–î–∞—Ç–∞'].max().date()
        else:
            min_date = max_date = date.today()
            st.warning("–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–∞—Ç—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑-–∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –¥–∞–Ω–Ω—ã—Ö")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞—Ç: {str(e)}")
        min_date = max_date = date.today()
        st.warning("–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–∞—Ç—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏")

    # –§–∏–ª—å—Ç—Ä—ã –≤ —Å–∞–π–¥–±–∞—Ä–µ
    with st.sidebar:
        st.header("‚è± –ü–µ—Ä–∏–æ–¥ –∞–Ω–∞–ª–∏–∑–∞")
        
        try:
            date_range = st.date_input(
                "–í—ã–±–µ—Ä–∏—Ç–µ –¥–∞—Ç—ã",
                value=(min_date, max_date),
                min_value=min_date,
                max_value=max_date,
                format="DD.MM.YYYY",
                key="date_range"
            )
            
            if len(date_range) != 2:
                st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –æ–±–µ –¥–∞—Ç—ã")
                st.stop()
                
            start_date, end_date = date_range
            if start_date > end_date:
                start_date, end_date = end_date, start_date
                st.warning("–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω –ø–æ—Ä—è–¥–æ–∫ –¥–∞—Ç")
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤—ã–±–æ—Ä–∞ –¥–∞—Ç—ã: {str(e)}")
            st.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–±–æ—Ä–µ –¥–∞—Ç. –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–∞—Ç—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.")
            start_date, end_date = min_date, max_date
        
        include_cancelled = st.checkbox("–£—á–∏—Ç—ã–≤–∞—Ç—å –æ—Ç–º–µ–Ω—ã", False, key="include_cancelled")
        
        st.header("üóÇ –§–∏–ª—å—Ç—Ä—ã")
        
        warehouse_col = None
        if not df.empty:
            warehouse_col = next((col for col in ['–¢–∏–ø —Å–∫–ª–∞–¥–∞', '–°–∫–ª–∞–¥'] if col in df.columns), None)
        
        if warehouse_col:
            warehouse_options = df[warehouse_col].unique().tolist()
            selected_warehouses = st.multiselect(
                "–¢–∏–ø —Å–∫–ª–∞–¥–∞",
                options=warehouse_options,
                default=warehouse_options[:1] if warehouse_options else [],
                key="warehouse_filter"
            )
        else:
            selected_warehouses = []
            st.warning("–î–∞–Ω–Ω—ã–µ –æ —Å–∫–ª–∞–¥–∞—Ö –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç")

    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤
    if st.button("–ü—Ä–∏–º–µ–Ω–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä—ã") or 'filtered_df' not in st.session_state:
        with st.spinner("–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤..."):
            try:
                if df.empty:
                    st.session_state.filtered_df = pd.DataFrame()
                    st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏")
                else:
                    filtered = df.copy()
                    
                    # –§–∏–ª—å—Ç—Ä –ø–æ –¥–∞—Ç–µ
                    if '–î–∞—Ç–∞' in filtered.columns:
                        filtered = filtered[
                            (filtered['–î–∞—Ç–∞'].dt.date >= start_date) & 
                            (filtered['–î–∞—Ç–∞'].dt.date <= end_date)
                        ]
                    
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã
                    if not include_cancelled and 'isCancel' in filtered.columns:
                        filtered = filtered[~filtered['isCancel']]
                    
                    if 'is_return' in filtered.columns:
                        filtered = filtered[~filtered['is_return']]
                    
                    if selected_warehouses and warehouse_col and warehouse_col in filtered.columns:
                        filtered = filtered[filtered[warehouse_col].isin(selected_warehouses)]
                    
                    st.session_state.filtered_df = filtered if not filtered.empty else pd.DataFrame()
                    
                    if st.session_state.filtered_df.empty:
                        st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ñ–∏–ª—å—Ç—Ä–∞–º")
                    else:
                        st.success(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(st.session_state.filtered_df)} –∑–∞–ø–∏—Å–µ–π")
                        
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {str(e)}\n{traceback.format_exc()}")
                st.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö")
                st.session_state.filtered_df = pd.DataFrame()

    # –ü–æ–ª—É—á–∞–µ–º –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    filtered_df = st.session_state.get('filtered_df', pd.DataFrame())
    
    if filtered_df.empty:
        st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è. –ò–∑–º–µ–Ω–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ–∏–ª—å—Ç—Ä–æ–≤.")
        st.stop()

    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
    st.header("üìä –ö–ª—é—á–µ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏")
    
    try:
        # –†–∞—Å—á–µ—Ç –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π
        revenue = filtered_df['–í—ã—Ä—É—á–∫–∞'].sum() if '–í—ã—Ä—É—á–∫–∞' in filtered_df.columns else 0
        order_count = filtered_df['srid'].nunique() if 'srid' in filtered_df.columns else 0
        avg_check = revenue / order_count if order_count > 0 else 0
        avg_spp = filtered_df['–°–ü–ü'].mean() if '–°–ü–ü' in filtered_df.columns else 0
        
        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
        cols = st.columns(4)
        cols[0].metric("–í—ã—Ä—É—á–∫–∞", f"{revenue:,.0f} ‚ÇΩ")
        cols[1].metric("–°—Ä–µ–¥–Ω–∏–π —á–µ–∫", f"{avg_check:,.0f} ‚ÇΩ")
        cols[2].metric("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–∫–∞–∑–æ–≤", order_count)
        cols[3].metric("–°—Ä–µ–¥–Ω–∏–π –°–ü–ü", f"{avg_spp:.2f}%" if not pd.isna(avg_spp) else "N/A")
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π: {str(e)}")
        st.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π")

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤–∫–ª–∞–¥–∫–∏ —Å –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–π
    tab1, tab2 = st.tabs(["üìà –î–∏–Ω–∞–º–∏–∫–∞ –ø—Ä–æ–¥–∞–∂", "üí∞ –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –≤—ã—Ä—É—á–∫–∏"])
    
    with tab1:
        st.subheader("–î–∏–Ω–∞–º–∏–∫–∞ –ø—Ä–æ–¥–∞–∂")
        
        try:
            if '–î–∞—Ç–∞' not in filtered_df.columns or '–í—ã—Ä—É—á–∫–∞' not in filtered_df.columns:
                st.warning("–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞")
            else:
                freq = st.radio("–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞", ["–î–µ–Ω—å", "–ù–µ–¥–µ–ª—è", "–ú–µ—Å—è—Ü"], horizontal=True)
                freq_map = {"–î–µ–Ω—å": "D", "–ù–µ–¥–µ–ª—è": "W", "–ú–µ—Å—è—Ü": "ME"}
                
                dynamic_df = filtered_df.groupby(pd.Grouper(key='–î–∞—Ç–∞', freq=freq_map[freq])).agg({
                    '–í—ã—Ä—É—á–∫–∞': 'sum',
                    'srid': 'nunique'
                }).reset_index()
                
                fig = go.Figure()
                fig.add_trace(go.Scatter(
                    x=dynamic_df['–î–∞—Ç–∞'], 
                    y=dynamic_df['–í—ã—Ä—É—á–∫–∞'],
                    name="–í—ã—Ä—É—á–∫–∞",
                    line=dict(color='blue')
                ))
                fig.add_trace(go.Scatter(
                    x=dynamic_df['–î–∞—Ç–∞'],
                    y=dynamic_df['srid'],
                    name="–ó–∞–∫–∞–∑—ã",
                    line=dict(color='orange'),
                    yaxis="y2"
                ))
                
                fig.update_layout(
                    title=f"–î–∏–Ω–∞–º–∏–∫–∞ –ø–æ {freq.lower()}–º",
                    yaxis=dict(title="–í—ã—Ä—É—á–∫–∞ (‚ÇΩ)"),
                    yaxis2=dict(title="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–∫–∞–∑–æ–≤", overlaying="y", side="right"),
                    hovermode="x unified"
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞: {str(e)}")
            st.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –¥–∏–Ω–∞–º–∏–∫–∏ –ø—Ä–æ–¥–∞–∂")

    with tab2:
        st.subheader("–î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –≤—ã—Ä—É—á–∫–∏")
        
        try:
            if '–í—ã—Ä—É—á–∫–∞' not in filtered_df.columns:
                st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –≤—ã—Ä—É—á–∫–µ")
            else:
                # –ê–Ω–∞–ª–∏–∑ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
                if '–ö–∞—Ç–µ–≥–æ—Ä–∏—è' in filtered_df.columns:
                    st.subheader("–ü–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º")
                    cat_df = filtered_df.groupby('–ö–∞—Ç–µ–≥–æ—Ä–∏—è')['–í—ã—Ä—É—á–∫–∞'].agg(['sum', 'count']).reset_index()
                    cat_df.columns = ['–ö–∞—Ç–µ–≥–æ—Ä–∏—è', '–í—ã—Ä—É—á–∫–∞', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ']
                    st.plotly_chart(
                        px.bar(cat_df, x='–ö–∞—Ç–µ–≥–æ—Ä–∏—è', y='–í—ã—Ä—É—á–∫–∞', title="–í—ã—Ä—É—á–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º"),
                        use_container_width=True
                    )
                
                # –ê–Ω–∞–ª–∏–∑ –ø–æ –±—Ä–µ–Ω–¥–∞–º
                if '–ë—Ä–µ–Ω–¥' in filtered_df.columns:
                    st.subheader("–ü–æ –±—Ä–µ–Ω–¥–∞–º")
                    brand_df = filtered_df.groupby('–ë—Ä–µ–Ω–¥')['–í—ã—Ä—É—á–∫–∞'].agg(['sum', 'count']).reset_index()
                    brand_df.columns = ['–ë—Ä–µ–Ω–¥', '–í—ã—Ä—É—á–∫–∞', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ']
                    st.plotly_chart(
                        px.bar(brand_df, x='–ë—Ä–µ–Ω–¥', y='–í—ã—Ä—É—á–∫–∞', title="–í—ã—Ä—É—á–∫–∞ –ø–æ –±—Ä–µ–Ω–¥–∞–º"),
                        use_container_width=True
                    )
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏: {str(e)}")
            st.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –≤—ã—Ä—É—á–∫–∏")

    # –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö
    with st.expander("üìÅ –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö"):
        st.subheader("–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
        
        if filtered_df.empty:
            st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞")
        else:
            st.dataframe(filtered_df.head(1000), height=400)
            
            # –ö–Ω–æ–ø–∫–∏ —ç–∫—Å–ø–æ—Ä—Ç–∞
            col1, col2 = st.columns(2)
            
            with col1:
                st.download_button(
                    label="–°–∫–∞—á–∞—Ç—å Excel",
                    data=filtered_df.to_excel(index=False),
                    file_name="wb_data.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            
            with col2:
                st.download_button(
                    label="–°–∫–∞—á–∞—Ç—å CSV",
                    data=filtered_df.to_csv(index=False).encode('utf-8'),
                    file_name="wb_data.csv",
                    mime="text/csv"
                )

if __name__ == "__main__":
    main()
