import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import json
from datetime import datetime, timedelta
import pytz
import numpy as np
import io
from openpyxl import Workbook
import requests
import gc
import logging
from typing import Optional, Tuple
import tempfile
import ijson  # –î–ª—è –ø–æ—Ç–æ–∫–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ JSON

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    layout="wide",
    page_title="WB Analytics Pro (Optimized)",
    page_icon="üìà",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': 'https://example.com',
        'Report a bug': "https://example.com",
        'About': "# –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ Wildberries —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤"
    }
)

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
MAX_JSON_SIZE_MB = 500  # –õ–∏–º–∏—Ç –¥–ª—è –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
JSON_LOAD_TIMEOUT = 600  # 10 –º–∏–Ω—É—Ç
CHUNK_SIZE = 1024 * 1024  # 1MB –¥–ª—è –ø–æ—Ç–æ–∫–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —Å –∞–Ω–Ω–æ—Ç–∞—Ü–∏–µ–π —Ç–∏–ø–æ–≤
global_df: Optional[pd.DataFrame] = None
global_excel_df: Optional[pd.DataFrame] = None

# –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –±–æ–ª—å—à–∏—Ö JSON —Ñ–∞–π–ª–æ–≤
@st.cache_data(ttl=3600, max_entries=3, show_spinner="–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
def load_large_json(url: str) -> pd.DataFrame:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –±–æ–ª—å—à–∏–µ JSON —Ñ–∞–π–ª—ã —Å –ø–æ—Ç–æ–∫–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""
    try:
        logger.info(f"–ù–∞—á–∞–ª–æ –∑–∞–≥—Ä—É–∑–∫–∏ –±–æ–ª—å—à–æ–≥–æ JSON —Ñ–∞–π–ª–∞ –∏–∑ {url}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞
        with requests.head(url, timeout=10) as r:
            size_mb = int(r.headers.get('content-length', 0)) / (1024 * 1024)
            if size_mb > MAX_JSON_SIZE_MB:
                st.warning(f"‚ö†Ô∏è –§–∞–π–ª –æ—á–µ–Ω—å –±–æ–ª—å—à–æ–π ({size_mb:.1f} –ú–ë). –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç...")

        # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –ø–æ—Ç–æ–∫–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        with tempfile.NamedTemporaryFile(mode='w+b') as tmp_file:
            # –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ —Å –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º
            with requests.get(url, stream=True, timeout=(30, JSON_LOAD_TIMEOUT)) as response:
                response.raise_for_status()
                total_size = int(response.headers.get('content-length', 0))
                downloaded = 0
                
                for chunk in response.iter_content(chunk_size=CHUNK_SIZE):
                    tmp_file.write(chunk)
                    downloaded += len(chunk)
                    progress = min(downloaded / total_size, 1.0) if total_size > 0 else 0
                    progress_bar.progress(progress)
                    status_text.text(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ: {downloaded/(1024*1024):.1f} –ú–ë / {total_size/(1024*1024):.1f} –ú–ë")

            # –ü–æ—Ç–æ–∫–æ–≤—ã–π –ø–∞—Ä—Å–∏–Ω–≥ JSON —Å –ø–æ–º–æ—â—å—é ijson
            tmp_file.seek(0)
            items = []
            status_text.text("–û–±—Ä–∞–±–æ—Ç–∫–∞ JSON...")
            
            # –ê–¥–∞–ø—Ç–∏—Ä—É–π—Ç–µ 'item' –ø–æ–¥ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –≤–∞—à–µ–≥–æ JSON
            for item in ijson.items(tmp_file, 'item'):
                items.append({
                    'date': item.get('date'),
                    'warehouseType': item.get('warehouseType'),
                    'regionName': item.get('regionName'),
                    'category': item.get('category'),
                    'brand': item.get('brand', '').lower(),
                    'subject': item.get('subject'),
                    'totalPrice': float(item.get('totalPrice', 0)),
                    'spp': float(item.get('spp', 0)),
                    'supplierArticle': str(item.get('supplierArticle', '')),
                    'is_return': str(item.get('srid', '')).startswith('R'),
                    'isCancel': bool(item.get('isCancel', False)),
                    'srid': item.get('srid')
                })
                
                # –õ–∏–º–∏—Ç –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ (–º–æ–∂–Ω–æ —É–±—Ä–∞—Ç—å –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ)
                if len(items) % 100000 == 0:
                    status_text.text(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(items)}")
            
            # –°–æ–∑–¥–∞–µ–º DataFrame
            df = pd.DataFrame(items)
            
            # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö
            if 'date' in df.columns:
                df['date'] = pd.to_datetime(df['date']).dt.tz_localize('Europe/Moscow')
            
            # –†—É—Å—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤
            column_mapping = {
                'date': '–î–∞—Ç–∞',
                'warehouseType': '–°–∫–ª–∞–¥',
                'regionName': '–†–µ–≥–∏–æ–Ω',
                'category': '–ö–∞—Ç–µ–≥–æ—Ä–∏—è',
                'brand': '–ë—Ä–µ–Ω–¥',
                'subject': '–ü–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è',
                'totalPrice': '–¶–µ–Ω–∞',
                'spp': '–°–ü–ü',
                'supplierArticle': '–ê—Ä—Ç–∏–∫—É–ª'
            }
            df = df.rename(columns={k: v for k, v in column_mapping.items() if k in df.columns})
            
            # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∞—Ä—Ç–∏–∫—É–ª–æ–≤
            if '–ê—Ä—Ç–∏–∫—É–ª' in df.columns:
                df['–ê—Ä—Ç–∏–∫—É–ª'] = df['–ê—Ä—Ç–∏–∫—É–ª'].apply(
                    lambda x: x[:len(x)//2] if len(x) == 20 and x[:10] == x[10:] else x
                )
            
            logger.info(f"–£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π")
            return df
            
    except requests.exceptions.RequestException as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}", exc_info=True)
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
        return pd.DataFrame()
    except Exception as e:
        logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)}", exc_info=True)
        st.error(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
        return pd.DataFrame()
    finally:
        progress_bar.empty()
        status_text.empty()

# –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ Excel
@st.cache_data(ttl=3600, max_entries=2)
def load_excel_data(url: str) -> pd.DataFrame:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ Excel —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –ø–∞–º—è—Ç–∏."""
    try:
        logger.info("–ù–∞—á–∞–ª–æ –∑–∞–≥—Ä—É–∑–∫–∏ Excel –¥–∞–Ω–Ω—ã—Ö")
        response = requests.get(url, timeout=(30, 300))
        response.raise_for_status()
        
        with io.BytesIO(response.content) as excel_file:
            df = pd.read_excel(
                excel_file,
                usecols=['–ê—Ä—Ç–∏–∫—É–ª –ø—Ä–æ–¥–∞–≤—Ü–∞', '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ'],
                dtype={'–ê—Ä—Ç–∏–∫—É–ª –ø—Ä–æ–¥–∞–≤—Ü–∞': 'string', '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ': 'string'}
            )
        
        if '–ê—Ä—Ç–∏–∫—É–ª –ø—Ä–æ–¥–∞–≤—Ü–∞' not in df.columns or '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ' not in df.columns:
            raise ValueError("–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ Excel —Ñ–∞–π–ª–µ")
        
        df = df.rename(columns={
            '–ê—Ä—Ç–∏–∫—É–ª –ø—Ä–æ–¥–∞–≤—Ü–∞': '–ê—Ä—Ç–∏–∫—É–ª',
            '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ': '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞'
        })
        
        logger.info(f"Excel –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã. –†–∞–∑–º–µ—Ä: {len(df)} —Å—Ç—Ä–æ–∫")
        return df[['–ê—Ä—Ç–∏–∫—É–ª', '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞']]
    
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Excel: {str(e)}", exc_info=True)
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ Excel —Ñ–∞–π–ª–∞: {str(e)}")
        return pd.DataFrame()

# –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —ç–∫—Å–ø–æ—Ä—Ç –≤ Excel
def to_excel(df: pd.DataFrame) -> bytes:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç DataFrame –≤ Excel —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –ø–∞–º—è—Ç–∏."""
    try:
        df_copy = df.copy()
        
        # –û—á–∏—Å—Ç–∫–∞ datetime –æ–±—ä–µ–∫—Ç–æ–≤
        datetime_cols = ['–î–∞—Ç–∞', 'lastChangeDate']
        for col in datetime_cols:
            if col in df_copy.columns:
                df_copy[col] = df_copy[col].dt.tz_localize(None)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±—É—Ñ–µ—Ä
        output = io.BytesIO()
        with pd.ExcelWriter(
            output,
            engine='openpyxl',
            mode='w',
            engine_kwargs={'options': {'strings_to_urls': False}}
        ) as writer:
            df_copy.to_excel(
                writer,
                index=False,
                sheet_name='SalesData',
                freeze_panes=(1, 0)
            )
        
        return output.getvalue()
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ Excel: {str(e)}", exc_info=True)
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ Excel —Ñ–∞–π–ª–∞: {str(e)}")
        raise

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö
def apply_filters(df: pd.DataFrame, date_range: Tuple[datetime.date, datetime.date], 
                 include_cancelled: bool, warehouse_type: list) -> pd.DataFrame:
    """–ü—Ä–∏–º–µ–Ω—è–µ—Ç —Ñ–∏–ª—å—Ç—Ä—ã –∫ –¥–∞–Ω–Ω—ã–º —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π."""
    try:
        filtered = df[
            (df['–î–∞—Ç–∞'].dt.date >= date_range[0]) &
            (df['–î–∞—Ç–∞'].dt.date <= date_range[1]) &
            (~df['is_return'])
        ].copy()
        
        if not include_cancelled:
            filtered = filtered[~filtered['isCancel']]
            
        if warehouse_type:
            filtered = filtered[filtered['–°–∫–ª–∞–¥'].isin(warehouse_type)]
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏
        for col in filtered.select_dtypes(include=['object']):
            filtered[col] = filtered[col].astype('string')
            
        return filtered
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {str(e)}", exc_info=True)
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
        raise

# –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
def main():
    global global_df, global_excel_df
    
    st.title("üîç Wildberries Analytics Pro (Optimized for Large Files)")
    
    # URL –¥–∞–Ω–Ω—ã—Ö
    json_url = "https://storage.yandexcloud.net/my-json-bucket-chat-wb/wb_dashboard/all_sales_data.json"
    excel_url = "https://storage.yandexcloud.net/my-json-bucket-chat-wb/14_04_2025_07_26_%D0%9E%D0%B1%D1%89%D0%B8%D0%B5_%D1%85%D0%B0%D1%80%D0%B0%D0%BA%D1%82%D0%B5%D1%80%D0%B8%D1%81%D1%82%D0%B8%D0%BA%D0%B8_%D0%BE%D0%B4%D0%BD%D0%B8%D0%BC_%D1%84%D0%B0%D0%B9%D0%BB%D0%BE%D0%BC.xlsx"
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
    if 'data_loaded' not in st.session_state:
        with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö (—ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤)..."):
            try:
                # –ó–∞–≥—Ä—É–∑–∫–∞ JSON —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º
                global_df = load_large_json(json_url)
                
                # –ó–∞–≥—Ä—É–∑–∫–∞ Excel
                if global_df is not None and not global_df.empty:
                    global_excel_df = load_excel_data(excel_url)
                    
                    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
                    if global_excel_df is not None and not global_excel_df.empty:
                        global_df = pd.merge(
                            global_df,
                            global_excel_df,
                            on='–ê—Ä—Ç–∏–∫—É–ª',
                            how='left',
                            validate='many_to_one'
                        )
                        st.session_state.data_loaded = True
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
                return
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
    if global_df is None or global_df.empty:
        st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
        return
    
    # –ö–Ω–æ–ø–∫–∞ —Å–±—Ä–æ—Å–∞ –∫—ç—à–∞
    if st.button("üîÑ –°–±—Ä–æ—Å–∏—Ç—å –∫—ç—à –∏ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ"):
        st.cache_data.clear()
        st.session_state.clear()
        global_df = None
        global_excel_df = None
        st.experimental_rerun()
    
    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –¥–∞—Ç
    min_date = global_df['–î–∞—Ç–∞'].min().date()
    max_date = global_df['–î–∞—Ç–∞'].max().date()
    
    # –°–∞–π–¥–±–∞—Ä —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏
    with st.sidebar:
        st.header("‚è± –ü–µ—Ä–∏–æ–¥ –∞–Ω–∞–ª–∏–∑–∞")
        try:
            date_range = st.date_input(
                "–í—ã–±–µ—Ä–∏—Ç–µ –¥–∞—Ç—ã",
                [min_date, max_date],
                min_value=min_date,
                max_value=max_date,
                format="DD.MM.YYYY"
            )
            if len(date_range) != 2:
                st.error("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç")
                st.stop()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤—ã–±–æ—Ä–∞ –¥–∞—Ç—ã: {str(e)}", exc_info=True)
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–±–æ—Ä–µ –¥–∞—Ç—ã: {str(e)}")
            st.stop()
        
        include_cancelled = st.checkbox("–£—á–∏—Ç—ã–≤–∞—Ç—å –æ—Ç–º–µ–Ω—ã", value=False)
        st.header("üóÇ –§–∏–ª—å—Ç—Ä—ã")
        warehouse_type = st.multiselect(
            "–¢–∏–ø —Å–∫–ª–∞–¥–∞",
            options=global_df['–°–∫–ª–∞–¥'].unique(),
            default=global_df['–°–∫–ª–∞–¥'].unique()[0] if len(global_df['–°–∫–ª–∞–¥'].unique()) > 0 else []
        )
    
    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤
    if 'filtered_df' not in st.session_state or st.button("–ü—Ä–∏–º–µ–Ω–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä—ã"):
        with st.spinner("–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤..."):
            try:
                st.session_state.filtered_df = apply_filters(
                    global_df,
                    date_range,
                    include_cancelled,
                    warehouse_type
                )
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {str(e)}")
                st.stop()
    
    filtered_df = st.session_state.get('filtered_df', pd.DataFrame())
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    if filtered_df.empty:
        st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ñ–∏–ª—å—Ç—Ä–∞–º")
        st.stop()
    
    # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    st.subheader("üîç –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
    cols = st.columns(3)
    cols[0].metric("–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π", len(filtered_df))
    cols[1].metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–∞–∫–∞–∑–æ–≤", filtered_df['srid'].nunique())
    cols[2].metric("–î—É–±–ª–∏–∫–∞—Ç–æ–≤ srid", filtered_df.duplicated(subset=['srid']).sum())
    
    # –ö–ª—é—á–µ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏
    st.header("üìä –ö–ª—é—á–µ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏")
    
    with st.spinner("–†–∞—Å—á–µ—Ç –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π..."):
        try:
            revenue = filtered_df['–¶–µ–Ω–∞'].sum()
            order_count = filtered_df['srid'].nunique()
            avg_check = revenue / order_count if order_count > 0 else 0
            avg_spp = filtered_df['–°–ü–ü'].mean()
            
            cols = st.columns(4)
            cols[0].metric("–í—ã—Ä—É—á–∫–∞", f"{revenue:,.0f} ‚ÇΩ")
            cols[1].metric("–°—Ä–µ–¥–Ω–∏–π —á–µ–∫", f"{avg_check:,.0f} ‚ÇΩ")
            cols[2].metric("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–∫–∞–∑–æ–≤", order_count)
            cols[3].metric("–°—Ä–µ–¥–Ω–∏–π –°–ü–ü", 
                          f"{avg_spp:.2f}%" if not pd.isna(avg_spp) else "N/A",
                          help="–°—Ä–µ–¥–Ω–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç —Å–∫–∏–¥–∫–∏ –ø–æ –ø—Ä–æ–¥–∞–∂–∞–º")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫: {str(e)}", exc_info=True)
            st.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π")
    
    # –í–∫–ª–∞–¥–∫–∏ –∞–Ω–∞–ª–∏–∑–∞
    tab1, tab2 = st.tabs(["üìà –î–∏–Ω–∞–º–∏–∫–∞ –ø—Ä–æ–¥–∞–∂", "üí∞ –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –≤—ã—Ä—É—á–∫–∏"])
    
    with tab1:
        st.subheader("–î–∏–Ω–∞–º–∏–∫–∞ –ø—Ä–æ–¥–∞–∂")
        try:
            freq = st.radio("–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞", ["–î–µ–Ω—å", "–ù–µ–¥–µ–ª—è", "–ú–µ—Å—è—Ü"], 
                          horizontal=True, key="freq_selector")
            freq_map = {"–î–µ–Ω—å": "D", "–ù–µ–¥–µ–ª—è": "W", "–ú–µ—Å—è—Ü": "ME"}
            
            with st.spinner("–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞..."):
                dynamic_df = filtered_df.groupby(
                    pd.Grouper(key='–î–∞—Ç–∞', freq=freq_map[freq])
                ).agg({
                    '–¶–µ–Ω–∞': 'sum',
                    'srid': 'nunique'
                }).reset_index()
                
                fig = go.Figure()
                fig.add_trace(go.Scatter(
                    x=dynamic_df['–î–∞—Ç–∞'],
                    y=dynamic_df['–¶–µ–Ω–∞'],
                    name="–í—ã—Ä—É—á–∫–∞",
                    line=dict(color='#1f77b4', width=2)
                ))
                fig.add_trace(go.Scatter(
                    x=dynamic_df['–î–∞—Ç–∞'],
                    y=dynamic_df['srid'],
                    name="–ó–∞–∫–∞–∑—ã",
                    line=dict(color='#ff7f0e', width=2),
                    yaxis="y2"
                ))
                
                fig.update_layout(
                    title=f"–î–∏–Ω–∞–º–∏–∫–∞ –ø–æ {freq.lower()}–º",
                    yaxis=dict(title="–í—ã—Ä—É—á–∫–∞ (‚ÇΩ)"),
                    yaxis2=dict(title="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–∫–∞–∑–æ–≤", overlaying="y", side="right"),
                    hovermode="x unified",
                    legend=dict(orientation="h", y=1.1)
                )
                st.plotly_chart(fig, use_container_width=True)
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞: {str(e)}", exc_info=True)
            st.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –¥–∏–Ω–∞–º–∏–∫–∏ –ø—Ä–æ–¥–∞–∂")
    
    with tab2:
        st.subheader("–î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –≤—ã—Ä—É—á–∫–∏")
        
        if st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—é", True, key="show_details"):
            with st.spinner("–ê–Ω–∞–ª–∏–∑ –≤—ã—Ä—É—á–∫–∏..."):
                try:
                    total_revenue = filtered_df['–¶–µ–Ω–∞'].sum()
                    
                    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
                    def display_revenue_analysis(df, group_col, title):
                        analysis_df = df.groupby(group_col).agg({
                            '–¶–µ–Ω–∞': ['sum', 'count'],
                            '–°–ü–ü': 'mean'
                        }).reset_index()
                        
                        analysis_df.columns = [group_col, '–í—ã—Ä—É—á–∫–∞', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', '–°—Ä–µ–¥–Ω–∏–π –°–ü–ü']
                        analysis_df['–î–æ–ª—è'] = (analysis_df['–í—ã—Ä—É—á–∫–∞'] / total_revenue) * 100
                        analysis_df['–°—Ä–µ–¥–Ω–∏–π –°–ü–ü'] = analysis_df['–°—Ä–µ–¥–Ω–∏–π –°–ü–ü'].round(2)
                        
                        st.subheader(title)
                        fig = px.bar(
                            analysis_df,
                            x=group_col,
                            y='–í—ã—Ä—É—á–∫–∞',
                            hover_data=['–î–æ–ª—è', '–°—Ä–µ–¥–Ω–∏–π –°–ü–ü'],
                            labels={'–í—ã—Ä—É—á–∫–∞': '–í—ã—Ä—É—á–∫–∞, ‚ÇΩ'},
                            title=title
                        )
                        st.plotly_chart(fig, use_container_width=True)
                        
                        analysis_df = analysis_df.sort_values('–í—ã—Ä—É—á–∫–∞', ascending=False)
                        st.dataframe(analysis_df)
                        
                        st.download_button(
                            label=f"–°–∫–∞—á–∞—Ç—å {title.lower()}",
                            data=to_excel(analysis_df),
                            file_name=f"{title.replace(' ', '_')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                        return analysis_df
                    
                    # –ê–Ω–∞–ª–∏–∑ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
                    cat_df = display_revenue_analysis(filtered_df, '–ö–∞—Ç–µ–≥–æ—Ä–∏—è', "–í—ã—Ä—É—á–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º")
                    selected_cat = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –∫–∞—Ç–µ–≥–æ—Ä–∏—é", cat_df['–ö–∞—Ç–µ–≥–æ—Ä–∏—è'].unique())
                    
                    # –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                    cat_details = filtered_df[filtered_df['–ö–∞—Ç–µ–≥–æ—Ä–∏—è'] == selected_cat]
                    subcat_df = display_revenue_analysis(cat_details, '–ü–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è', 
                                                       f"–í—ã—Ä—É—á–∫–∞ –ø–æ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è–º ({selected_cat})")
                    
                    # –ê–Ω–∞–ª–∏–∑ –ø–æ –±—Ä–µ–Ω–¥–∞–º
                    brand_df = display_revenue_analysis(filtered_df, '–ë—Ä–µ–Ω–¥', "–í—ã—Ä—É—á–∫–∞ –ø–æ –±—Ä–µ–Ω–¥–∞–º")
                    
                    # –ü–æ—á–∞—Å–æ–≤–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –¥–ª—è –æ–¥–Ω–æ–≥–æ –¥–Ω—è
                    if date_range[0] == date_range[1]:
                        st.subheader("–ü–æ—á–∞—Å–æ–≤–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞")
                        hourly_df = filtered_df.groupby(filtered_df['–î–∞—Ç–∞'].dt.hour).agg({
                            '–¶–µ–Ω–∞': 'sum',
                            'srid': 'nunique'
                        }).reset_index().rename(columns={'–î–∞—Ç–∞': '–ß–∞—Å'})
                        
                        fig = px.bar(
                            hourly_df,
                            x='–ß–∞—Å',
                            y='–¶–µ–Ω–∞',
                            hover_data=['srid'],
                            labels={'srid': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–∫–∞–∑–æ–≤'},
                            title='–í—ã—Ä—É—á–∫–∞ –ø–æ —á–∞—Å–∞–º'
                        )
                        st.plotly_chart(fig, use_container_width=True)
                        
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏: {str(e)}", exc_info=True)
                    st.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –≤—ã—Ä—É—á–∫–∏")
    
    # –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö
    with st.expander("üìÅ –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö", expanded=False):
        st.subheader("–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
        st.dataframe(
            filtered_df.head(1000),
            height=400,
            use_container_width=True
        )
        
        cols = st.columns(2)
        cols[0].download_button(
            label="üì• Excel (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π)",
            data=to_excel(filtered_df),
            file_name="wb_analytics.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
        cols[1].download_button(
            label="üì• CSV (—Å–∂–∞—Ç—ã–π)",
            data=filtered_df.to_csv(index=False, encoding='utf-8').encode('utf-8'),
            file_name="wb_analytics.csv",
            mime="text/csv"
        )

if __name__ == "__main__":
    try:
        main()
    finally:
        # –ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
        gc.collect()
