import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import json
from datetime import datetime, timedelta
import pytz
import numpy as np
import io
from openpyxl import Workbook
import requests
import gc
import logging
from typing import Optional, Tuple

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    layout="wide",
    page_title="WB Analytics Pro",
    page_icon="üìà",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': 'https://example.com',
        'Report a bug': "https://example.com",
        'About': "# –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ Wildberries"
    }
)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —Å –∞–Ω–Ω–æ—Ç–∞—Ü–∏–µ–π —Ç–∏–ø–æ–≤
global_df: Optional[pd.DataFrame] = None
global_excel_df: Optional[pd.DataFrame] = None

# –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ JSON —Å —á–∞–Ω–∫–∏—Ä–æ–≤–∞–Ω–∏–µ–º
@st.cache_data(ttl=3600, max_entries=3, show_spinner="–ó–∞–≥—Ä—É–∑–∫–∞ JSON –¥–∞–Ω–Ω—ã—Ö...")
def load_data(url: str) -> pd.DataFrame:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ JSON URL —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –ø–∞–º—è—Ç–∏."""
    try:
        logger.info("–ù–∞—á–∞–ª–æ –∑–∞–≥—Ä—É–∑–∫–∏ JSON –¥–∞–Ω–Ω—ã—Ö")
        response = requests.get(url, timeout=(3.05, 27), stream=True)
        response.raise_for_status()
        
        # –ß–∞–Ω–∫–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
        chunks = []
        for chunk in response.iter_content(chunk_size=1024*1024):  # 1MB chunks
            chunks.append(chunk)
            if len(chunks) > 50:  # –õ–∏–º–∏—Ç ~50MB
                raise MemoryError("–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        
        data = json.loads(b''.join(chunks).decode('utf-8'))
        df = pd.DataFrame(data)

        # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        datetime_cols = ['date', 'lastChangeDate']
        for col in datetime_cols:
            if col in df.columns:
                df[col] = pd.to_datetime(df[col]).dt.tz_localize('Europe/Moscow')
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö
        type_optimizations = {
            'is_return': lambda x: x.str.startswith('R') if pd.api.types.is_string_dtype(x) else False,
            'revenue': 'totalPrice',
            'week': lambda x: x.dt.isocalendar().week,
            'month': lambda x: x.dt.month,
            'isCancel': lambda x: x.fillna(False)
        }
        
        for col, func in type_optimizations.items():
            if isinstance(func, str) and func in df.columns:
                df[col] = df[func]
            else:
                try:
                    df[col] = func(df['date'] if col in ['week', 'month'] else df.get(col, pd.Series()))
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ {col}: {str(e)}")
                    df[col] = None

        # –†—É—Å—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤
        column_mapping = {
            'date': '–î–∞—Ç–∞',
            'warehouseType': '–°–∫–ª–∞–¥',
            'regionName': '–†–µ–≥–∏–æ–Ω',
            'category': '–ö–∞—Ç–µ–≥–æ—Ä–∏—è',
            'brand': '–ë—Ä–µ–Ω–¥',
            'subject': '–ü–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è',
            'totalPrice': '–¶–µ–Ω–∞',
            'revenue': '–í—ã—Ä—É—á–∫–∞',
            'spp': '–°–ü–ü',
            'supplierArticle': '–ê—Ä—Ç–∏–∫—É–ª'
        }
        df = df.rename(columns={k: v for k, v in column_mapping.items() if k in df.columns})

        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å—Ç—Ä–æ–∫–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        str_cols = ['–ë—Ä–µ–Ω–¥', '–ê—Ä—Ç–∏–∫—É–ª', '–ö–∞—Ç–µ–≥–æ—Ä–∏—è', '–ü–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è']
        for col in str_cols:
            if col in df.columns:
                df[col] = df[col].astype('string')
        
        df['–ë—Ä–µ–Ω–¥'] = df['–ë—Ä–µ–Ω–¥'].str.lower()
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∞—Ä—Ç–∏–∫—É–ª–æ–≤
        if '–ê—Ä—Ç–∏–∫—É–ª' in df.columns:
            df['–ê—Ä—Ç–∏–∫—É–ª'] = df['–ê—Ä—Ç–∏–∫—É–ª'].apply(
                lambda x: x[:len(x)//2] if len(x) == 20 and x[:10] == x[10:] else x
            )

        logger.info(f"JSON –¥–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã. –†–∞–∑–º–µ—Ä: {len(df)} —Å—Ç—Ä–æ–∫")
        return df
    
    except requests.exceptions.RequestException as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}", exc_info=True)
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
        return pd.DataFrame()
    except MemoryError as e:
        logger.error(str(e), exc_info=True)
        st.error("–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥–∞–Ω–Ω—ã–µ –º–µ–Ω—å—à–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞.")
        return pd.DataFrame()
    except Exception as e:
        logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)}", exc_info=True)
        st.error(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
        return pd.DataFrame()

# –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ Excel
@st.cache_data(ttl=3600, max_entries=2)
def load_excel_data(url: str) -> pd.DataFrame:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ Excel —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –ø–∞–º—è—Ç–∏."""
    try:
        logger.info("–ù–∞—á–∞–ª–æ –∑–∞–≥—Ä—É–∑–∫–∏ Excel –¥–∞–Ω–Ω—ã—Ö")
        response = requests.get(url, timeout=(3.05, 27))
        response.raise_for_status()
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±—É—Ñ–µ—Ä –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
        with io.BytesIO(response.content) as excel_file:
            # –ß–∏—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
            df = pd.read_excel(
                excel_file,
                usecols=['–ê—Ä—Ç–∏–∫—É–ª –ø—Ä–æ–¥–∞–≤—Ü–∞', '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ'],
                dtype={'–ê—Ä—Ç–∏–∫—É–ª –ø—Ä–æ–¥–∞–≤—Ü–∞': 'string', '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ': 'string'}
            )
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        required_columns = ['–ê—Ä—Ç–∏–∫—É–ª –ø—Ä–æ–¥–∞–≤—Ü–∞', '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ']
        if not all(col in df.columns for col in required_columns):
            raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {required_columns}")
        
        # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
        df = df.rename(columns={
            '–ê—Ä—Ç–∏–∫—É–ª –ø—Ä–æ–¥–∞–≤—Ü–∞': '–ê—Ä—Ç–∏–∫—É–ª',
            '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ': '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞'
        })
        
        logger.info(f"Excel –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã. –†–∞–∑–º–µ—Ä: {len(df)} —Å—Ç—Ä–æ–∫")
        return df[['–ê—Ä—Ç–∏–∫—É–ª', '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞']]
    
    except requests.exceptions.RequestException as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ Excel: {str(e)}", exc_info=True)
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ Excel: {str(e)}")
        return pd.DataFrame()
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ Excel: {str(e)}", exc_info=True)
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ Excel —Ñ–∞–π–ª–∞: {str(e)}")
        return pd.DataFrame()

# –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —ç–∫—Å–ø–æ—Ä—Ç –≤ Excel
def to_excel(df: pd.DataFrame) -> bytes:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç DataFrame –≤ Excel —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –ø–∞–º—è—Ç–∏."""
    try:
        # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é —Å –æ—á–∏—Å—Ç–∫–æ–π datetime –¥–ª—è Excel
        df_copy = df.copy()
        datetime_cols = ['–î–∞—Ç–∞', 'lastChangeDate']
        
        for col in datetime_cols:
            if col in df_copy.columns:
                df_copy[col] = df_copy[col].dt.tz_localize(None)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±—É—Ñ–µ—Ä –∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        output = io.BytesIO()
        with pd.ExcelWriter(
            output,
            engine='openpyxl',
            mode='w',
            engine_kwargs={'options': {'strings_to_urls': False}}
        ) as writer:
            df_copy.to_excel(
                writer,
                index=False,
                sheet_name='SalesData',
                freeze_panes=(1, 0)
            )
        
        return output.getvalue()
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ Excel: {str(e)}", exc_info=True)
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ Excel —Ñ–∞–π–ª–∞: {str(e)}")
        raise

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö
def apply_filters(df: pd.DataFrame, date_range: Tuple[datetime.date, datetime.date], 
                 include_cancelled: bool, warehouse_type: list) -> pd.DataFrame:
    """–ü—Ä–∏–º–µ–Ω—è–µ—Ç —Ñ–∏–ª—å—Ç—Ä—ã –∫ –¥–∞–Ω–Ω—ã–º —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π."""
    try:
        filtered = df[
            (df['–î–∞—Ç–∞'].dt.date >= date_range[0]) &
            (df['–î–∞—Ç–∞'].dt.date <= date_range[1]) &
            (~df['is_return'])
        ].copy()
        
        if not include_cancelled:
            filtered = filtered[~filtered['isCancel']]
            
        if warehouse_type:
            filtered = filtered[filtered['–°–∫–ª–∞–¥'].isin(warehouse_type)]
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏
        for col in filtered.select_dtypes(include=['object']):
            filtered[col] = filtered[col].astype('string')
            
        return filtered
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {str(e)}", exc_info=True)
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
        raise

# –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
def main():
    global global_df, global_excel_df
    
    st.title("üîç Wildberries Analytics Pro (Optimized)")
    
    # URL –¥–∞–Ω–Ω—ã—Ö
    json_url = "https://storage.yandexcloud.net/my-json-bucket-chat-wb/wb_dashboard/all_sales_data.json"
    excel_url = "https://storage.yandexcloud.net/my-json-bucket-chat-wb/14_04_2025_07_26_%D0%9E%D0%B1%D1%89%D0%B8%D0%B5_%D1%85%D0%B0%D1%80%D0%B0%D0%BA%D1%82%D0%B5%D1%80%D0%B8%D1%81%D1%82%D0%B8%D0%BA%D0%B8_%D0%BE%D0%B4%D0%BD%D0%B8%D0%BC_%D1%84%D0%B0%D0%B9%D0%BB%D0%BE%D0%BC.xlsx"
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º
    if 'data_loaded' not in st.session_state:
        with st.spinner("–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö..."):
            progress_bar = st.progress(0)
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ JSON
            global_df = load_data(json_url)
            progress_bar.progress(40)
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ Excel
            global_excel_df = load_excel_data(excel_url)
            progress_bar.progress(80)
            
            if not global_df.empty and not global_excel_df.empty:
                try:
                    # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ
                    global_df = pd.merge(
                        global_df,
                        global_excel_df,
                        on='–ê—Ä—Ç–∏–∫—É–ª',
                        how='left',
                        validate='many_to_one'
                    )
                    st.session_state.data_loaded = True
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è: {str(e)}", exc_info=True)
                    st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
                    return
            progress_bar.progress(100)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
    if global_df is None or global_df.empty:
        st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
        return
    
    # –ö–Ω–æ–ø–∫–∞ —Å–±—Ä–æ—Å–∞ –∫—ç—à–∞
    if st.button("üîÑ –°–±—Ä–æ—Å–∏—Ç—å –∫—ç—à –∏ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ"):
        st.cache_data.clear()
        st.session_state.clear()
        global_df = None
        global_excel_df = None
        st.experimental_rerun()
    
    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –¥–∞—Ç
    min_date = global_df['–î–∞—Ç–∞'].min().date()
    max_date = global_df['–î–∞—Ç–∞'].max().date()
    
    # –°–∞–π–¥–±–∞—Ä —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏
    with st.sidebar:
        st.header("‚è± –ü–µ—Ä–∏–æ–¥ –∞–Ω–∞–ª–∏–∑–∞")
        try:
            date_range = st.date_input(
                "–í—ã–±–µ—Ä–∏—Ç–µ –¥–∞—Ç—ã",
                [min_date, max_date],
                min_value=min_date,
                max_value=max_date,
                format="DD.MM.YYYY"
            )
            if len(date_range) != 2:
                st.error("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç")
                st.stop()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤—ã–±–æ—Ä–∞ –¥–∞—Ç—ã: {str(e)}", exc_info=True)
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–±–æ—Ä–µ –¥–∞—Ç—ã: {str(e)}")
            st.stop()
        
        include_cancelled = st.checkbox("–£—á–∏—Ç—ã–≤–∞—Ç—å –æ—Ç–º–µ–Ω—ã", value=False)
        st.header("üóÇ –§–∏–ª—å—Ç—Ä—ã")
        warehouse_type = st.multiselect(
            "–¢–∏–ø —Å–∫–ª–∞–¥–∞",
            options=global_df['–°–∫–ª–∞–¥'].unique(),
            default=global_df['–°–∫–ª–∞–¥'].unique()[0] if len(global_df['–°–∫–ª–∞–¥'].unique()) > 0 else []
        )
    
    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤ session_state
    if 'filtered_df' not in st.session_state or st.button("–ü—Ä–∏–º–µ–Ω–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä—ã"):
        with st.spinner("–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤..."):
            try:
                st.session_state.filtered_df = apply_filters(
                    global_df,
                    date_range,
                    include_cancelled,
                    warehouse_type
                )
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {str(e)}")
                st.stop()
    
    filtered_df = st.session_state.get('filtered_df', pd.DataFrame())
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    if filtered_df.empty:
        st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ñ–∏–ª—å—Ç—Ä–∞–º")
        st.stop()
    
    # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    st.subheader("üîç –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π", len(filtered_df))
    with col2:
        st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–∞–∫–∞–∑–æ–≤", filtered_df['srid'].nunique())
    with col3:
        st.metric("–î—É–±–ª–∏–∫–∞—Ç–æ–≤ srid", filtered_df.duplicated(subset=['srid']).sum())
    
    # –ö–ª—é—á–µ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏
    st.header("üìä –ö–ª—é—á–µ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏")
    
    with st.spinner("–†–∞—Å—á–µ—Ç –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π..."):
        try:
            revenue = filtered_df['–í—ã—Ä—É—á–∫–∞'].sum()
            order_count = filtered_df['srid'].nunique()
            avg_check = revenue / order_count if order_count > 0 else 0
            avg_spp = filtered_df['–°–ü–ü'].mean()
            
            cols = st.columns(4)
            cols[0].metric("–í—ã—Ä—É—á–∫–∞", f"{revenue:,.0f} ‚ÇΩ")
            cols[1].metric("–°—Ä–µ–¥–Ω–∏–π —á–µ–∫", f"{avg_check:,.0f} ‚ÇΩ")
            cols[2].metric("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–∫–∞–∑–æ–≤", order_count)
            cols[3].metric("–°—Ä–µ–¥–Ω–∏–π –°–ü–ü", 
                          f"{avg_spp:.2f}%" if not pd.isna(avg_spp) else "N/A",
                          help="–°—Ä–µ–¥–Ω–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç —Å–∫–∏–¥–∫–∏ –ø–æ –ø—Ä–æ–¥–∞–∂–∞–º")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫: {str(e)}", exc_info=True)
            st.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π")
    
    # –í–∫–ª–∞–¥–∫–∏ –∞–Ω–∞–ª–∏–∑–∞
    tab1, tab2 = st.tabs(["üìà –î–∏–Ω–∞–º–∏–∫–∞ –ø—Ä–æ–¥–∞–∂", "üí∞ –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –≤—ã—Ä—É—á–∫–∏"])
    
    with tab1:
        st.subheader("–î–∏–Ω–∞–º–∏–∫–∞ –ø—Ä–æ–¥–∞–∂")
        try:
            freq = st.radio("–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞", ["–î–µ–Ω—å", "–ù–µ–¥–µ–ª—è", "–ú–µ—Å—è—Ü"], 
                          horizontal=True, key="freq_selector")
            freq_map = {"–î–µ–Ω—å": "D", "–ù–µ–¥–µ–ª—è": "W", "–ú–µ—Å—è—Ü": "ME"}
            
            with st.spinner("–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞..."):
                dynamic_df = filtered_df.groupby(
                    pd.Grouper(key='–î–∞—Ç–∞', freq=freq_map[freq])
                ).agg({
                    '–í—ã—Ä—É—á–∫–∞': 'sum',
                    'srid': 'nunique'
                }).reset_index()
                
                fig = go.Figure()
                fig.add_trace(go.Scatter(
                    x=dynamic_df['–î–∞—Ç–∞'],
                    y=dynamic_df['–í—ã—Ä—É—á–∫–∞'],
                    name="–í—ã—Ä—É—á–∫–∞",
                    line=dict(color='#1f77b4', width=2)
                ))
                fig.add_trace(go.Scatter(
                    x=dynamic_df['–î–∞—Ç–∞'],
                    y=dynamic_df['srid'],
                    name="–ó–∞–∫–∞–∑—ã",
                    line=dict(color='#ff7f0e', width=2),
                    yaxis="y2"
                ))
                
                fig.update_layout(
                    title=f"–î–∏–Ω–∞–º–∏–∫–∞ –ø–æ {freq.lower()}–º",
                    yaxis=dict(title="–í—ã—Ä—É—á–∫–∞ (‚ÇΩ)"),
                    yaxis2=dict(title="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–∫–∞–∑–æ–≤", overlaying="y", side="right"),
                    hovermode="x unified",
                    legend=dict(orientation="h", y=1.1)
                )
                st.plotly_chart(fig, use_container_width=True)
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞: {str(e)}", exc_info=True)
            st.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –¥–∏–Ω–∞–º–∏–∫–∏ –ø—Ä–æ–¥–∞–∂")
    
    with tab2:
        st.subheader("–î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –≤—ã—Ä—É—á–∫–∏")
        
        if st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—é", True, key="show_details"):
            with st.spinner("–ê–Ω–∞–ª–∏–∑ –≤—ã—Ä—É—á–∫–∏..."):
                try:
                    total_revenue = filtered_df['–í—ã—Ä—É—á–∫–∞'].sum()
                    
                    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
                    def display_revenue_analysis(df, group_col, title):
                        analysis_df = df.groupby(group_col).agg({
                            '–í—ã—Ä—É—á–∫–∞': ['sum', 'count'],
                            '–°–ü–ü': 'mean'
                        }).reset_index()
                        
                        analysis_df.columns = [group_col, '–í—ã—Ä—É—á–∫–∞', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', '–°—Ä–µ–¥–Ω–∏–π –°–ü–ü']
                        analysis_df['–î–æ–ª—è'] = (analysis_df['–í—ã—Ä—É—á–∫–∞'] / total_revenue) * 100
                        analysis_df['–°—Ä–µ–¥–Ω–∏–π –°–ü–ü'] = analysis_df['–°—Ä–µ–¥–Ω–∏–π –°–ü–ü'].round(2)
                        
                        st.subheader(title)
                        fig = px.bar(
                            analysis_df,
                            x=group_col,
                            y='–í—ã—Ä—É—á–∫–∞',
                            hover_data=['–î–æ–ª—è', '–°—Ä–µ–¥–Ω–∏–π –°–ü–ü'],
                            labels={'–í—ã—Ä—É—á–∫–∞': '–í—ã—Ä—É—á–∫–∞, ‚ÇΩ'},
                            title=title
                        )
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –≤—ã—Ä—É—á–∫–µ
                        analysis_df = analysis_df.sort_values('–í—ã—Ä—É—á–∫–∞', ascending=False)
                        st.dataframe(analysis_df)
                        
                        # –ö–Ω–æ–ø–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞
                        st.download_button(
                            label=f"–°–∫–∞—á–∞—Ç—å {title.lower()}",
                            data=to_excel(analysis_df),
                            file_name=f"{title.replace(' ', '_')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                        return analysis_df
                    
                    # –ê–Ω–∞–ª–∏–∑ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
                    cat_df = display_revenue_analysis(filtered_df, '–ö–∞—Ç–µ–≥–æ—Ä–∏—è', "–í—ã—Ä—É—á–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º")
                    selected_cat = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –∫–∞—Ç–µ–≥–æ—Ä–∏—é", cat_df['–ö–∞—Ç–µ–≥–æ—Ä–∏—è'].unique())
                    
                    # –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                    cat_details = filtered_df[filtered_df['–ö–∞—Ç–µ–≥–æ—Ä–∏—è'] == selected_cat]
                    subcat_df = display_revenue_analysis(cat_details, '–ü–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è', 
                                                       f"–í—ã—Ä—É—á–∫–∞ –ø–æ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è–º ({selected_cat})")
                    
                    # –ê–Ω–∞–ª–∏–∑ –ø–æ –±—Ä–µ–Ω–¥–∞–º
                    brand_df = display_revenue_analysis(filtered_df, '–ë—Ä–µ–Ω–¥', "–í—ã—Ä—É—á–∫–∞ –ø–æ –±—Ä–µ–Ω–¥–∞–º")
                    
                    # –ü–æ—á–∞—Å–æ–≤–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –¥–ª—è –æ–¥–Ω–æ–≥–æ –¥–Ω—è
                    if date_range[0] == date_range[1]:
                        st.subheader("–ü–æ—á–∞—Å–æ–≤–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞")
                        hourly_df = filtered_df.groupby(filtered_df['–î–∞—Ç–∞'].dt.hour).agg({
                            '–í—ã—Ä—É—á–∫–∞': 'sum',
                            'srid': 'nunique'
                        }).reset_index().rename(columns={'–î–∞—Ç–∞': '–ß–∞—Å'})
                        
                        fig = px.bar(
                            hourly_df,
                            x='–ß–∞—Å',
                            y='–í—ã—Ä—É—á–∫–∞',
                            hover_data=['srid'],
                            labels={'srid': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–∫–∞–∑–æ–≤'},
                            title='–í—ã—Ä—É—á–∫–∞ –ø–æ —á–∞—Å–∞–º'
                        )
                        st.plotly_chart(fig, use_container_width=True)
                        
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏: {str(e)}", exc_info=True)
                    st.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –≤—ã—Ä—É—á–∫–∏")
    
    # –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö
    with st.expander("üìÅ –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö", expanded=False):
        st.subheader("–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
        st.dataframe(
            filtered_df.head(1000),
            height=400,
            use_container_width=True
        )
        
        cols = st.columns(2)
        cols[0].download_button(
            label="üì• Excel (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π)",
            data=to_excel(filtered_df),
            file_name="wb_analytics.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
        cols[1].download_button(
            label="üì• CSV (—Å–∂–∞—Ç—ã–π)",
            data=filtered_df.to_csv(index=False, encoding='utf-8').encode('utf-8'),
            file_name="wb_analytics.csv",
            mime="text/csv"
        )

if __name__ == "__main__":
    try:
        main()
    finally:
        # –ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
        gc.collect()
