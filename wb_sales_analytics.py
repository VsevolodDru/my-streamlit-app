import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import json
from datetime import datetime, date, timedelta
import pytz
import numpy as np
import io
from openpyxl import Workbook
import requests
import gc
import logging
from typing import Optional, Tuple
import tempfile
import os
import traceback
import time

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
os.environ['STREAMLIT_SERVER_ENABLE_WATCHER'] = 'false'
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    layout="wide",
    page_title="WB Analytics Pro",
    page_icon="üìà",
    initial_sidebar_state="expanded"
)

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
MAX_RETRIES = 3
RETRY_DELAY = 5
MAX_JSON_SIZE_MB = 500
JSON_LOAD_TIMEOUT = 600
CHUNK_SIZE = 1024 * 1024

# –•—Ä–∞–Ω–∏–ª–∏—â–µ –¥–ª—è –æ—à–∏–±–æ–∫ –∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
if 'error_log' not in st.session_state:
    st.session_state['error_log'] = []

def log_error(message: str):
    """–î–æ–±–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ –≤ –ª–æ–≥"""
    logger.error(message)
    st.session_state['error_log'].append(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] –û—à–∏–±–∫–∞: {message}")

def log_warning(message: str):
    """–î–æ–±–∞–≤–ª—è–µ—Ç –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –≤ –ª–æ–≥"""
    logger.warning(message)
    st.session_state['error_log'].append(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: {message}")

class DataLoader:
    @staticmethod
    def load_with_retry(url: str, loader_func, **kwargs):
        for attempt in range(MAX_RETRIES):
            try:
                return loader_func(url, **kwargs)
            except Exception as e:
                error_msg = f"–ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} –Ω–µ —É–¥–∞–ª–∞—Å—å: {str(e)}\n{traceback.format_exc()}"
                log_error(error_msg)
                if attempt < MAX_RETRIES - 1:
                    time.sleep(RETRY_DELAY)
        return pd.DataFrame()

    @staticmethod
    def load_large_json(url: str) -> pd.DataFrame:
        try:
            logger.info(f"Starting JSON load from {url}")
            
            with requests.head(url, timeout=10) as r:
                if r.status_code != 200:
                    log_error(f"URL –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ö–æ–¥ —Å—Ç–∞—Ç—É—Å–∞: {r.status_code}")
                    return pd.DataFrame()

            progress_bar = st.progress(0)
            status_text = st.empty()
            
            response = requests.get(url, stream=True, timeout=(30, JSON_LOAD_TIMEOUT))
            response.raise_for_status()
            
            chunks = []
            total_size = int(response.headers.get('content-length', 0))
            downloaded = 0
            
            for chunk in response.iter_content(chunk_size=CHUNK_SIZE):
                chunks.append(chunk)
                downloaded += len(chunk)
                progress = min(downloaded / total_size, 1.0) if total_size > 0 else 0
                progress_bar.progress(progress)
                status_text.text(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ: {downloaded/(1024*1024):.1f} –ú–ë / {total_size/(1024*1024):.1f} –ú–ë")
            
            status_text.text("–û–±—Ä–∞–±–æ—Ç–∫–∞ JSON...")
            
            try:
                data = json.loads(b''.join(chunks).decode('utf-8'))
            except json.JSONDecodeError as e:
                log_error(f"–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ JSON: {str(e)}")
                return pd.DataFrame()
            
            if not data:
                log_warning("–ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π JSON")
                return pd.DataFrame()
            
            try:
                df = pd.DataFrame(data)
                if df.empty:
                    log_warning("–î–∞–Ω–Ω—ã–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ JSON")
                    return df
                
                datetime_cols = ['date', 'lastChangeDate']
                for col in datetime_cols:
                    if col in df.columns:
                        try:
                            df[col] = pd.to_datetime(df[col], errors='coerce')
                            if df[col].dt.tz is None:
                                df[col] = df[col].dt.tz_localize('Europe/Moscow')
                        except Exception as e:
                            log_warning(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞—Ç—ã –≤ –∫–æ–ª–æ–Ω–∫–µ {col}: {str(e)}")
                            df[col] = pd.to_datetime(df[col], errors='coerce')
                
                df['is_return'] = df.get('srid', '').astype(str).str.startswith('R')
                df['revenue'] = df.get('totalPrice', 0)
                
                if 'date' in df.columns:
                    try:
                        df['week'] = df['date'].dt.isocalendar().week
                        df['month'] = df['date'].dt.month
                    except:
                        pass
                
                df['isCancel'] = df.get('isCancel', False)

                column_mapping = {
                    'date': '–î–∞—Ç–∞',
                    'warehouseName': '–°–∫–ª–∞–¥',
                    'warehouse': '–°–∫–ª–∞–¥',
                    'warehouseType': '–¢–∏–ø —Å–∫–ª–∞–¥–∞',
                    'regionName': '–†–µ–≥–∏–æ–Ω',
                    'category': '–ö–∞—Ç–µ–≥–æ—Ä–∏—è',
                    'brand': '–ë—Ä–µ–Ω–¥',
                    'subject': '–ü–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è',
                    'totalPrice': '–¶–µ–Ω–∞',
                    'revenue': '–í—ã—Ä—É—á–∫–∞',
                    'spp': '–°–ü–ü',
                    'supplierArticle': '–ê—Ä—Ç–∏–∫—É–ª'
                }
                
                df = df.rename(columns={k: v for k, v in column_mapping.items() if k in df.columns})

                str_cols = ['–ë—Ä–µ–Ω–¥', '–ê—Ä—Ç–∏–∫—É–ª', '–ö–∞—Ç–µ–≥–æ—Ä–∏—è', '–ü–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è', '–°–∫–ª–∞–¥', '–¢–∏–ø —Å–∫–ª–∞–¥–∞']
                for col in str_cols:
                    if col in df.columns:
                        df[col] = df[col].astype(str).str.strip()
                
                if '–ë—Ä–µ–Ω–¥' in df.columns:
                    df['–ë—Ä–µ–Ω–¥'] = df['–ë—Ä–µ–Ω–¥'].str.lower()
                
                if '–ê—Ä—Ç–∏–∫—É–ª' in df.columns:
                    df['–ê—Ä—Ç–∏–∫—É–ª'] = df['–ê—Ä—Ç–∏–∫—É–ª'].apply(
                        lambda x: x[:len(x)//2] if isinstance(x, str) and len(x) == 20 and x[:10] == x[10:] else x
                    )

                logger.info(f"–£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π")
                return df
                
            except Exception as e:
                log_error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
                return pd.DataFrame()
                
        except Exception as e:
            log_error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {str(e)}\n{traceback.format_exc()}")
            return pd.DataFrame()
        finally:
            if 'progress_bar' in locals(): progress_bar.empty()
            if 'status_text' in locals(): status_text.empty()

    @staticmethod
    def load_excel_data(url: str) -> pd.DataFrame:
        try:
            logger.info(f"Starting Excel load from {url}")
            
            try:
                with requests.head(url, timeout=10) as r:
                    if r.status_code != 200:
                        log_error(f"Excel URL –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ö–æ–¥ —Å—Ç–∞—Ç—É—Å–∞: {r.status_code}")
                        return pd.DataFrame()
            except requests.RequestException as e:
                log_error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Excel URL: {str(e)}")
                return pd.DataFrame()

            response = requests.get(url, timeout=(30, 300))
            response.raise_for_status()
            
            with io.BytesIO(response.content) as excel_file:
                try:
                    df = pd.read_excel(
                        excel_file,
                        usecols=['–ê—Ä—Ç–∏–∫—É–ª –ø—Ä–æ–¥–∞–≤—Ü–∞', '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ'],
                        dtype={'–ê—Ä—Ç–∏–∫—É–ª –ø—Ä–æ–¥–∞–≤—Ü–∞': 'string', '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ': 'string'}
                    )
                except Exception as e:
                    log_error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è Excel: {str(e)}")
                    return pd.DataFrame()
            
            if df.empty:
                log_warning("Excel —Ñ–∞–π–ª –ø—É—Å—Ç")
                return df
            
            required_cols = ['–ê—Ä—Ç–∏–∫—É–ª –ø—Ä–æ–¥–∞–≤—Ü–∞', '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ']
            if not all(col in df.columns for col in required_cols):
                log_error("–í Excel –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏")
                return pd.DataFrame()
            
            df = df.rename(columns={
                '–ê—Ä—Ç–∏–∫—É–ª –ø—Ä–æ–¥–∞–≤—Ü–∞': '–ê—Ä—Ç–∏–∫—É–ª',
                '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ': '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞'
            })
            
            df['–ê—Ä—Ç–∏–∫—É–ª'] = df['–ê—Ä—Ç–∏–∫—É–ª'].astype(str).str.strip()
            df['–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞'] = df['–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞'].astype(str).str.strip()
            
            logger.info(f"Excel –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã. –†–∞–∑–º–µ—Ä: {len(df)} —Å—Ç—Ä–æ–∫")
            return df[['–ê—Ä—Ç–∏–∫—É–ª', '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞']].drop_duplicates(subset=['–ê—Ä—Ç–∏–∫—É–ª'])
        
        except Exception as e:
            log_error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Excel: {str(e)}\n{traceback.format_exc()}")
            return pd.DataFrame()

def to_excel(df: pd.DataFrame) -> bytes:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç DataFrame –≤ Excel —Ñ–∞–π–ª –≤ –ø–∞–º—è—Ç–∏"""
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False)
    return output.getvalue()

def main():
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è
    if 'data_loaded' not in st.session_state:
        st.session_state.update({
            'data_loaded': False,
            'load_error': None,
            'df': pd.DataFrame(),
            'excel_df': pd.DataFrame(),
            'filtered_df': pd.DataFrame(),
            'previous_fbs': True,
            'previous_fbo': True
        })

    st.title("üîç Wildberries Analytics Pro")
    
    # URL –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
    DATA_SOURCES = {
        "fbs": "https://storage.yandexcloud.net/my-json-bucket-chat-wb/wb_dashboard/all_sales_data.json",
        "fbo": "https://storage.yandexcloud.net/my-json-bucket-chat-wb/wb_dashboard/all_sales_data_FBO.json",
        "excel": "https://storage.yandexcloud.net/my-json-bucket-chat-wb/14_04_2025_07_26_%D0%9E%D0%B1%D1%89%D0%B8%D0%B5_%D1%85%D0%B0%D1%80%D0%B0%D0%BA%D1%82%D0%B5%D1%80%D0%B8%D1%81%D1%82%D0%B8%D0%BA%D0%B8_%D0%BE%D0%B4%D0%BD%D0%B8%D0%BC_%D1%84%D0%B0%D0%B9%D0%BB%D0%BE%D0%BC.xlsx"
    }

    # –§–∏–ª—å—Ç—Ä—ã –≤ —Å–∞–π–¥–±–∞—Ä–µ
    with st.sidebar:
        st.header("‚è± –ü–µ—Ä–∏–æ–¥ –∞–Ω–∞–ª–∏–∑–∞")
        
        # –§–∏–ª—å—Ç—Ä –ø–æ —Å—Ö–µ–º–∞–º –ø—Ä–æ–¥–∞–∂
        st.header("üì¶ –°—Ö–µ–º—ã –ø—Ä–æ–¥–∞–∂")
        use_fbs = st.checkbox("FBS", value=st.session_state.get('previous_fbs', True), key="use_fbs")
        use_fbo = st.checkbox("FBO", value=st.session_state.get('previous_fbo', True), key="use_fbo")

        if not (use_fbs or use_fbo):
            st.warning("–í—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω—É —Å—Ö–µ–º—É –ø—Ä–æ–¥–∞–∂ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö.")
            st.stop()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∏–∑–º–µ–Ω–∏–ª–∏—Å—å –ª–∏ —á–µ–∫–±–æ–∫—Å—ã, —á—Ç–æ–±—ã –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ
        if (use_fbs != st.session_state.get('previous_fbs', True) or 
            use_fbo != st.session_state.get('previous_fbo', True)):
            st.session_state.update({
                'data_loaded': False,
                'load_error': None,
                'previous_fbs': use_fbs,
                'previous_fbo': use_fbo
            })

    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    if not st.session_state.data_loaded and st.session_state.load_error is None:
        with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ..."):
            try:
                combined_data = pd.DataFrame()

                if use_fbs:
                    fbs_data = DataLoader.load_with_retry(DATA_SOURCES["fbs"], DataLoader.load_large_json)
                    if not fbs_data.empty:
                        fbs_data['–°—Ö–µ–º–∞ –ø—Ä–æ–¥–∞–∂'] = 'FBS'
                        combined_data = pd.concat([combined_data, fbs_data], ignore_index=True)
                        logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ FBS: {len(fbs_data)} –∑–∞–ø–∏—Å–µ–π")
                    else:
                        log_warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –ø–æ FBS")

                if use_fbo:
                    fbo_data = DataLoader.load_with_retry(DATA_SOURCES["fbo"], DataLoader.load_large_json)
                    if not fbo_data.empty:
                        fbo_data['–°—Ö–µ–º–∞ –ø—Ä–æ–¥–∞–∂'] = 'FBO'
                        combined_data = pd.concat([combined_data, fbo_data], ignore_index=True)
                        logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ FBO: {len(fbo_data)} –∑–∞–ø–∏—Å–µ–π")
                    else:
                        log_warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –ø–æ FBO")

                if not combined_data.empty:
                    excel_data = DataLoader.load_with_retry(DATA_SOURCES["excel"], DataLoader.load_excel_data)
                    
                    if not excel_data.empty:
                        try:
                            merged_df = pd.merge(
                                combined_data,
                                excel_data,
                                on='–ê—Ä—Ç–∏–∫—É–ª',
                                how='left'
                            )
                            st.session_state.update({
                                'df': merged_df,
                                'excel_df': excel_data,
                                'data_loaded': True,
                                'load_error': None
                            })
                        except Exception as e:
                            st.session_state.load_error = f"–û—à–∏–±–∫–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {str(e)}"
                            log_error(f"–û—à–∏–±–∫–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
                    else:
                        st.session_state.update({
                            'df': combined_data,
                            'data_loaded': True,
                            'load_error': "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å Excel –¥–∞–Ω–Ω—ã–µ"
                        })
                        log_warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å Excel –¥–∞–Ω–Ω—ã–µ")
                else:
                    st.session_state.load_error = "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ"
                    log_error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
                    
            except Exception as e:
                st.session_state.load_error = f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}"
                log_error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}\n{traceback.format_exc()}")

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –∑–∞–≥—Ä—É–∑–∫–∏
    if st.session_state.load_error:
        st.warning("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤–∫–ª–∞–¥–∫—É '–õ–æ–≥–∏ –∏ –æ—à–∏–±–∫–∏'.")
        
        if st.button("–ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Å–Ω–æ–≤–∞"):
            st.session_state.update({
                'data_loaded': False,
                'load_error': None
            })
            st.rerun()
        
        st.stop()
    
    if not st.session_state.data_loaded:
        st.warning("–î–∞–Ω–Ω—ã–µ –µ—â–µ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è...")
        st.stop()

    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ session state
    df = st.session_state.df
    excel_df = st.session_state.excel_df

    # –ö–Ω–æ–ø–∫–∞ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
    if st.button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ"):
        st.session_state.update({
            'data_loaded': False,
            'load_error': None
        })
        st.rerun()

    # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –¥–∞—Ç
    try:
        if not df.empty and '–î–∞—Ç–∞' in df.columns:
            min_date = df['–î–∞—Ç–∞'].min().date()
            max_date = df['–î–∞—Ç–∞'].max().date()
        else:
            min_date = max_date = date.today()
            log_warning("–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–∞—Ç—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑-–∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –¥–∞–Ω–Ω—ã—Ö")
    except Exception as e:
        log_error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞—Ç: {str(e)}")
        min_date = max_date = date.today()
        log_warning("–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–∞—Ç—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏")

    # –§–∏–ª—å—Ç—Ä—ã –≤ —Å–∞–π–¥–±–∞—Ä–µ (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ)
    with st.sidebar:
        try:
            date_range = st.date_input(
                "–í—ã–±–µ—Ä–∏—Ç–µ –¥–∞—Ç—ã",
                value=(min_date, max_date),
                min_value=min_date,
                max_value=max_date,
                format="DD.MM.YYYY",
                key="date_range"
            )
            
            if len(date_range) != 2:
                st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –æ–±–µ –¥–∞—Ç—ã")
                st.stop()
                
            start_date, end_date = date_range
            if start_date > end_date:
                start_date, end_date = end_date, start_date
                st.warning("–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω –ø–æ—Ä—è–¥–æ–∫ –¥–∞—Ç")
                
        except Exception as e:
            log_error(f"–û—à–∏–±–∫–∞ –≤—ã–±–æ—Ä–∞ –¥–∞—Ç—ã: {str(e)}")
            st.warning("–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–±–æ—Ä–µ –¥–∞—Ç. –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–∞—Ç—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.")
            start_date, end_date = min_date, max_date
        
        include_cancelled = st.checkbox("–£—á–∏—Ç—ã–≤–∞—Ç—å –æ—Ç–º–µ–Ω—ã", False, key="include_cancelled")
        
        st.header("üóÇ –§–∏–ª—å—Ç—Ä—ã")
        
        warehouse_col = None
        if not df.empty:
            warehouse_col = next((col for col in ['–¢–∏–ø —Å–∫–ª–∞–¥–∞', '–°–∫–ª–∞–¥'] if col in df.columns), None)
        
        if warehouse_col:
            warehouse_options = df[warehouse_col].unique().tolist()
            selected_warehouses = st.multiselect(
                "–¢–∏–ø —Å–∫–ª–∞–¥–∞",
                options=warehouse_options,
                default=warehouse_options[:1] if warehouse_options else [],
                key="warehouse_filter"
            )
        else:
            selected_warehouses = []
            st.warning("–î–∞–Ω–Ω—ã–µ –æ —Å–∫–ª–∞–¥–∞—Ö –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç")

    # –í–∫–ª–∞–¥–∫–∏ —Å –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–π –∏ –ª–æ–≥–∞–º–∏
    tab1, tab2, tab3 = st.tabs(["üìà –î–∏–Ω–∞–º–∏–∫–∞ –ø—Ä–æ–¥–∞–∂", "üîç –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑", "üîî –õ–æ–≥–∏ –∏ –æ—à–∏–±–∫–∏"])

    with tab3:
        st.subheader("–õ–æ–≥–∏ –∏ –æ—à–∏–±–∫–∏")
        if st.session_state['error_log']:
            for log_entry in st.session_state['error_log']:
                st.text(log_entry)
        else:
            st.info("–û—à–∏–±–æ–∫ –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π –ø–æ–∫–∞ –Ω–µ—Ç.")
        
        if st.button("–û—á–∏—Å—Ç–∏—Ç—å –ª–æ–≥–∏"):
            st.session_state['error_log'] = []
            st.rerun()

    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤
    if st.button("–ü—Ä–∏–º–µ–Ω–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä—ã") or 'filtered_df' not in st.session_state:
        with st.spinner("–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤..."):
            try:
                if df.empty:
                    st.session_state.filtered_df = pd.DataFrame()
                    st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏")
                else:
                    filtered = df.copy()
                    
                    # –§–∏–ª—å—Ç—Ä –ø–æ –¥–∞—Ç–µ
                    if '–î–∞—Ç–∞' in filtered.columns:
                        filtered = filtered[
                            (filtered['–î–∞—Ç–∞'].dt.date >= start_date) & 
                            (filtered['–î–∞—Ç–∞'].dt.date <= end_date)
                        ]
                    
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã
                    if not include_cancelled and 'isCancel' in filtered.columns:
                        filtered = filtered[~filtered['isCancel']]
                    
                    if 'is_return' in filtered.columns:
                        filtered = filtered[~filtered['is_return']]
                    
                    if selected_warehouses and warehouse_col and warehouse_col in filtered.columns:
                        filtered = filtered[filtered[warehouse_col].isin(selected_warehouses)]
                    
                    st.session_state.filtered_df = filtered if not filtered.empty else pd.DataFrame()
                    
                    if st.session_state.filtered_df.empty:
                        st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ñ–∏–ª—å—Ç—Ä–∞–º")
                    else:
                        st.success(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(st.session_state.filtered_df)} –∑–∞–ø–∏—Å–µ–π")
                        
            except Exception as e:
                log_error(f"–û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {str(e)}\n{traceback.format_exc()}")
                st.warning("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤–∫–ª–∞–¥–∫—É '–õ–æ–≥–∏ –∏ –æ—à–∏–±–∫–∏'.")

    # –ü–æ–ª—É—á–∞–µ–º –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    filtered_df = st.session_state.get('filtered_df', pd.DataFrame())
    
    if filtered_df.empty:
        st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è. –ò–∑–º–µ–Ω–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ–∏–ª—å—Ç—Ä–æ–≤.")
        st.stop()

    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
    st.header("üìä –ö–ª—é—á–µ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏")
    
    try:
        # –†–∞—Å—á–µ—Ç –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π
        revenue = filtered_df['–í—ã—Ä—É—á–∫–∞'].sum() if '–í—ã—Ä—É—á–∫–∞' in filtered_df.columns else 0
        order_count = filtered_df['srid'].nunique() if 'srid' in filtered_df.columns else 0
        avg_check = revenue / order_count if order_count > 0 else 0
        avg_spp = filtered_df['–°–ü–ü'].mean() if '–°–ü–ü' in filtered_df.columns else 0
        
        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
        cols = st.columns(4)
        cols[0].metric("–í—ã—Ä—É—á–∫–∞", f"{revenue:,.0f} ‚ÇΩ")
        cols[1].metric("–°—Ä–µ–¥–Ω–∏–π —á–µ–∫", f"{avg_check:,.0f} ‚ÇΩ")
        cols[2].metric("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–∫–∞–∑–æ–≤", order_count)
        cols[3].metric("–°—Ä–µ–¥–Ω–∏–π –°–ü–ü", f"{avg_spp:.2f}%" if not pd.isna(avg_spp) else "N/A")
        
    except Exception as e:
        log_error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π: {str(e)}")
        st.warning("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤–∫–ª–∞–¥–∫—É '–õ–æ–≥–∏ –∏ –æ—à–∏–±–∫–∏'.")

    with tab1:
        st.subheader("–î–∏–Ω–∞–º–∏–∫–∞ –ø—Ä–æ–¥–∞–∂")
        
        try:
            if '–î–∞—Ç–∞' not in filtered_df.columns or '–í—ã—Ä—É—á–∫–∞' not in filtered_df.columns:
                st.warning("–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞")
            else:
                freq = st.radio("–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞", ["–î–µ–Ω—å", "–ù–µ–¥–µ–ª—è", "–ú–µ—Å—è—Ü"], horizontal=True)
                freq_map = {"–î–µ–Ω—å": "D", "–ù–µ–¥–µ–ª—è": "W", "–ú–µ—Å—è—Ü": "ME"}
                
                dynamic_df = filtered_df.groupby(pd.Grouper(key='–î–∞—Ç–∞', freq=freq_map[freq])).agg({
                    '–í—ã—Ä—É—á–∫–∞': 'sum',
                    'srid': 'nunique'
                }).reset_index()
                
                fig = go.Figure()
                fig.add_trace(go.Scatter(
                    x=dynamic_df['–î–∞—Ç–∞'], 
                    y=dynamic_df['–í—ã—Ä—É—á–∫–∞'],
                    name="–í—ã—Ä—É—á–∫–∞",
                    line=dict(color='blue')
                ))
                fig.add_trace(go.Scatter(
                    x=dynamic_df['–î–∞—Ç–∞'],
                    y=dynamic_df['srid'],
                    name="–ó–∞–∫–∞–∑—ã",
                    line=dict(color='orange'),
                    yaxis="y2"
                ))
                
                fig.update_layout(
                    title=f"–î–∏–Ω–∞–º–∏–∫–∞ –ø–æ {freq.lower()}–º",
                    yaxis=dict(title="–í—ã—Ä—É—á–∫–∞ (‚ÇΩ)"),
                    yaxis2=dict(title="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–∫–∞–∑–æ–≤", overlaying="y", side="right"),
                    hovermode="x unified"
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
        except Exception as e:
            log_error(f"–û—à–∏–±–∫–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞: {str(e)}")
            st.warning("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –¥–∏–Ω–∞–º–∏–∫–∏ –ø—Ä–æ–¥–∞–∂. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤–∫–ª–∞–¥–∫—É '–õ–æ–≥–∏ –∏ –æ—à–∏–±–∫–∏'.")

    with tab2:
        st.subheader("–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑")
        
        try:
            if filtered_df.empty:
                st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            else:
                # –í—ã–±–æ—Ä —Ç–∏–ø–∞ –∞–Ω–∞–ª–∏–∑–∞
                analysis_type = st.selectbox(
                    "–¢–∏–ø –∞–Ω–∞–ª–∏–∑–∞",
                    options=['–ö–∞—Ç–µ–≥–æ—Ä–∏—è', '–ë—Ä–µ–Ω–¥', '–ü–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è', '–°–∫–ª–∞–¥', '–°—Ö–µ–º–∞ –ø—Ä–æ–¥–∞–∂'],
                    index=0
                )
                
                if analysis_type in filtered_df.columns:
                    # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
                    analysis_df = filtered_df.groupby(analysis_type).agg({
                        '–í—ã—Ä—É—á–∫–∞': 'sum',
                        'srid': 'nunique',
                        '–°–ü–ü': 'mean'
                    }).reset_index()
                    
                    analysis_df.columns = [analysis_type, '–í—ã—Ä—É—á–∫–∞', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–∫–∞–∑–æ–≤', '–°—Ä–µ–¥–Ω–∏–π –°–ü–ü']
                    analysis_df['–°—Ä–µ–¥–Ω–∏–π —á–µ–∫'] = analysis_df['–í—ã—Ä—É—á–∫–∞'] / analysis_df['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–∫–∞–∑–æ–≤']
                    analysis_df['–î–æ–ª—è –≤—ã—Ä—É—á–∫–∏'] = (analysis_df['–í—ã—Ä—É—á–∫–∞'] / analysis_df['–í—ã—Ä—É—á–∫–∞'].sum()) * 100
                    
                    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞
                    analysis_df = analysis_df.sort_values('–í—ã—Ä—É—á–∫–∞', ascending=False)
                    
                    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã
                    st.dataframe(
                        analysis_df.style.format({
                            '–í—ã—Ä—É—á–∫–∞': '{:,.0f} ‚ÇΩ',
                            '–°—Ä–µ–¥–Ω–∏–π —á–µ–∫': '{:,.0f} ‚ÇΩ',
                            '–î–æ–ª—è –≤—ã—Ä—É—á–∫–∏': '{:.1f}%',
                            '–°—Ä–µ–¥–Ω–∏–π –°–ü–ü': '{:.1f}%'
                        }),
                        height=600,
                        use_container_width=True
                    )
                    
                    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
                    fig = px.bar(
                        analysis_df.head(20),
                        x=analysis_type,
                        y='–í—ã—Ä—É—á–∫–∞',
                        hover_data=['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–∫–∞–∑–æ–≤', '–°—Ä–µ–¥–Ω–∏–π —á–µ–∫', '–î–æ–ª—è –≤—ã—Ä—É—á–∫–∏'],
                        title=f"–¢–æ–ø 20 {analysis_type.lower()} –ø–æ –≤—ã—Ä—É—á–∫–µ"
                    )
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –∞—Ä—Ç–∏–∫—É–ª–∞–º –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–π
                    if analysis_type in ['–ö–∞—Ç–µ–≥–æ—Ä–∏—è', '–ü–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è']:
                        st.subheader(f"–î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –∞—Ä—Ç–∏–∫—É–ª–∞–º ({analysis_type})")
                        
                        # –í—ã–±–æ—Ä –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏/–ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                        selected_item = st.selectbox(
                            f"–í—ã–±–µ—Ä–∏—Ç–µ {analysis_type.lower()} –¥–ª—è –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏",
                            options=analysis_df[analysis_type].unique(),
                            index=0
                        )
                        
                        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏/–ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                        item_data = filtered_df[filtered_df[analysis_type] == selected_item]
                        
                        if not item_data.empty:
                            # –ê–Ω–∞–ª–∏–∑ –ø–æ –∞—Ä—Ç–∏–∫—É–ª–∞–º
                            articles_df = item_data.groupby(['–ê—Ä—Ç–∏–∫—É–ª', '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞']).agg({
                                '–í—ã—Ä—É—á–∫–∞': 'sum',
                                'srid': 'nunique',
                                '–°–ü–ü': 'mean'
                            }).reset_index()
                            
                            articles_df.columns = ['–ê—Ä—Ç–∏–∫—É–ª', '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞', '–í—ã—Ä—É—á–∫–∞', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–∫–∞–∑–æ–≤', '–°—Ä–µ–¥–Ω–∏–π –°–ü–ü']
                            articles_df['–°—Ä–µ–¥–Ω–∏–π —á–µ–∫'] = articles_df['–í—ã—Ä—É—á–∫–∞'] / articles_df['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–∫–∞–∑–æ–≤']
                            articles_df['–î–æ–ª—è –≤—ã—Ä—É—á–∫–∏'] = (articles_df['–í—ã—Ä—É—á–∫–∞'] / articles_df['–í—ã—Ä—É—á–∫–∞'].sum()) * 100
                            
                            # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞
                            articles_df = articles_df.sort_values('–í—ã—Ä—É—á–∫–∞', ascending=False)
                            
                            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã
                            st.dataframe(
                                articles_df.style.format({
                                    '–í—ã—Ä—É—á–∫–∞': '{:,.0f} ‚ÇΩ',
                                    '–°—Ä–µ–¥–Ω–∏–π —á–µ–∫': '{:,.0f} ‚ÇΩ',
                                    '–î–æ–ª—è –≤—ã—Ä—É—á–∫–∏': '{:.1f}%',
                                    '–°—Ä–µ–¥–Ω–∏–π –°–ü–ü': '{:.1f}%'
                                }),
                                height=600,
                                use_container_width=True
                            )
                            
                            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
                            fig = px.bar(
                                articles_df.head(20),
                                x='–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞',
                                y='–í—ã—Ä—É—á–∫–∞',
                                hover_data=['–ê—Ä—Ç–∏–∫—É–ª', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–∫–∞–∑–æ–≤', '–°—Ä–µ–¥–Ω–∏–π —á–µ–∫', '–î–æ–ª—è –≤—ã—Ä—É—á–∫–∏'],
                                title=f"–¢–æ–ø 20 —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ –≤—ã—Ä—É—á–∫–µ ({selected_item})"
                            )
                            st.plotly_chart(fig, use_container_width=True)
                        else:
                            st.warning(f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–π {analysis_type.lower()}")
                else:
                    st.warning(f"–í –¥–∞–Ω–Ω—ã—Ö –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–ª–æ–Ω–∫–∞ {analysis_type}")
                
        except Exception as e:
            log_error(f"–û—à–∏–±–∫–∞ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}")
            st.warning("–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∞–Ω–∞–ª–∏–∑–∞. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤–∫–ª–∞–¥–∫—É '–õ–æ–≥–∏ –∏ –æ—à–∏–±–∫–∏'.")

    # –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö
    with st.expander("üìÅ –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö"):
        st.subheader("–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
        
        if filtered_df.empty:
            st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞")
        else:
            st.dataframe(filtered_df.head(1000), height=400)
            
            # –ö–Ω–æ–ø–∫–∏ —ç–∫—Å–ø–æ—Ä—Ç–∞
            col1, col2 = st.columns(2)
            
            with col1:
                st.download_button(
                    label="–°–∫–∞—á–∞—Ç—å Excel",
                    data=to_excel(filtered_df),
                    file_name="wb_data.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            
            with col2:
                st.download_button(
                    label="–°–∫–∞—á–∞—Ç—å CSV",
                    data=filtered_df.to_csv(index=False).encode('utf-8'),
                    file_name="wb_data.csv",
                    mime="text/csv"
                )

if __name__ == "__main__":
    main()
